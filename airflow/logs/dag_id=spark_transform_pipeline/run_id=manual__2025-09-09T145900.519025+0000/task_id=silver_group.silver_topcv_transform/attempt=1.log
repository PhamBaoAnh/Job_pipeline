[2025-09-09T14:59:07.064+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-09-09T14:59:07.143+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: spark_transform_pipeline.silver_group.silver_topcv_transform manual__2025-09-09T14:59:00.519025+00:00 [queued]>
[2025-09-09T14:59:07.158+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: spark_transform_pipeline.silver_group.silver_topcv_transform manual__2025-09-09T14:59:00.519025+00:00 [queued]>
[2025-09-09T14:59:07.159+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-09-09T14:59:07.198+0000] {taskinstance.py:2330} INFO - Executing <Task(SparkSubmitOperator): silver_group.silver_topcv_transform> on 2025-09-09 14:59:00.519025+00:00
[2025-09-09T14:59:07.216+0000] {standard_task_runner.py:63} INFO - Started process 2056 to run task
[2025-09-09T14:59:07.226+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'spark_transform_pipeline', 'silver_group.silver_topcv_transform', 'manual__2025-09-09T14:59:00.519025+00:00', '--job-id', '120', '--raw', '--subdir', 'DAGS_FOLDER/etl_jobs_dag.py', '--cfg-path', '/tmp/tmpcjb8n28t']
[2025-09-09T14:59:07.233+0000] {standard_task_runner.py:91} INFO - Job 120: Subtask silver_group.silver_topcv_transform
[2025-09-09T14:59:07.441+0000] {task_command.py:426} INFO - Running <TaskInstance: spark_transform_pipeline.silver_group.silver_topcv_transform manual__2025-09-09T14:59:00.519025+00:00 [running]> on host 118acb478e13
[2025-09-09T14:59:07.804+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='spark_transform_pipeline' AIRFLOW_CTX_TASK_ID='silver_group.silver_topcv_transform' AIRFLOW_CTX_EXECUTION_DATE='2025-09-09T14:59:00.519025+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-09-09T14:59:00.519025+00:00'
[2025-09-09T14:59:07.805+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-09-09T14:59:07.850+0000] {base.py:84} INFO - Using connection ID 'spark_default' for task execution.
[2025-09-09T14:59:07.851+0000] {spark_submit.py:351} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.jars.packages=org.apache.hadoop:hadoop-aws:3.4.1,com.amazonaws:aws-java-sdk-bundle:1.12.367 --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=minio --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --jars /opt/custom-jars/aws-java-sdk-bundle-1.12.262.jar,/opt/custom-jars/hadoop-aws-3.4.1.jar --name arrow-spark --verbose /opt/spark-jobs/elt/transform/silver_topcv_transform.py
[2025-09-09T14:59:09.028+0000] {spark_submit.py:521} INFO - WARNING: Using incubator modules: jdk.incubator.vector
[2025-09-09T14:59:11.619+0000] {spark_submit.py:521} INFO - Parsed arguments:
[2025-09-09T14:59:11.621+0000] {spark_submit.py:521} INFO - master                  spark://spark-master:7077
[2025-09-09T14:59:11.623+0000] {spark_submit.py:521} INFO - remote                  null
[2025-09-09T14:59:11.625+0000] {spark_submit.py:521} INFO - deployMode              null
[2025-09-09T14:59:11.627+0000] {spark_submit.py:521} INFO - executorMemory          null
[2025-09-09T14:59:11.629+0000] {spark_submit.py:521} INFO - executorCores           null
[2025-09-09T14:59:11.631+0000] {spark_submit.py:521} INFO - totalExecutorCores      null
[2025-09-09T14:59:11.633+0000] {spark_submit.py:521} INFO - propertiesFile          null
[2025-09-09T14:59:11.634+0000] {spark_submit.py:521} INFO - driverMemory            null
[2025-09-09T14:59:11.635+0000] {spark_submit.py:521} INFO - driverCores             null
[2025-09-09T14:59:11.638+0000] {spark_submit.py:521} INFO - driverExtraClassPath    null
[2025-09-09T14:59:11.639+0000] {spark_submit.py:521} INFO - driverExtraLibraryPath  null
[2025-09-09T14:59:11.641+0000] {spark_submit.py:521} INFO - driverExtraJavaOptions  null
[2025-09-09T14:59:11.642+0000] {spark_submit.py:521} INFO - supervise               false
[2025-09-09T14:59:11.644+0000] {spark_submit.py:521} INFO - queue                   null
[2025-09-09T14:59:11.646+0000] {spark_submit.py:521} INFO - numExecutors            null
[2025-09-09T14:59:11.646+0000] {spark_submit.py:521} INFO - files                   null
[2025-09-09T14:59:11.647+0000] {spark_submit.py:521} INFO - pyFiles                 null
[2025-09-09T14:59:11.649+0000] {spark_submit.py:521} INFO - archives                null
[2025-09-09T14:59:11.650+0000] {spark_submit.py:521} INFO - mainClass               null
[2025-09-09T14:59:11.651+0000] {spark_submit.py:521} INFO - primaryResource         file:/opt/spark-jobs/elt/transform/silver_topcv_transform.py
[2025-09-09T14:59:11.655+0000] {spark_submit.py:521} INFO - name                    arrow-spark
[2025-09-09T14:59:11.658+0000] {spark_submit.py:521} INFO - childArgs               []
[2025-09-09T14:59:11.659+0000] {spark_submit.py:521} INFO - jars                    file:/opt/custom-jars/aws-java-sdk-bundle-1.12.262.jar,file:/opt/custom-jars/hadoop-aws-3.4.1.jar
[2025-09-09T14:59:11.661+0000] {spark_submit.py:521} INFO - packages                org.apache.hadoop:hadoop-aws:3.4.1,com.amazonaws:aws-java-sdk-bundle:1.12.367
[2025-09-09T14:59:11.662+0000] {spark_submit.py:521} INFO - packagesExclusions      null
[2025-09-09T14:59:11.663+0000] {spark_submit.py:521} INFO - repositories            null
[2025-09-09T14:59:11.664+0000] {spark_submit.py:521} INFO - verbose                 true
[2025-09-09T14:59:11.666+0000] {spark_submit.py:521} INFO - 
[2025-09-09T14:59:11.666+0000] {spark_submit.py:521} INFO - Spark properties used, including those specified through
[2025-09-09T14:59:11.667+0000] {spark_submit.py:521} INFO - --conf and those from the properties file null:
[2025-09-09T14:59:11.667+0000] {spark_submit.py:521} INFO - (spark.hadoop.fs.s3a.access.key,*********(redacted))
[2025-09-09T14:59:11.672+0000] {spark_submit.py:521} INFO - (spark.hadoop.fs.s3a.connection.ssl.enabled,false)
[2025-09-09T14:59:11.673+0000] {spark_submit.py:521} INFO - (spark.hadoop.fs.s3a.endpoint,http://minio:9000)
[2025-09-09T14:59:11.674+0000] {spark_submit.py:521} INFO - (spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)
[2025-09-09T14:59:11.675+0000] {spark_submit.py:521} INFO - (spark.hadoop.fs.s3a.path.style.access,true)
[2025-09-09T14:59:11.676+0000] {spark_submit.py:521} INFO - (spark.hadoop.fs.s3a.secret.key,*********(redacted))
[2025-09-09T14:59:11.680+0000] {spark_submit.py:521} INFO - (spark.jars.packages,org.apache.hadoop:hadoop-aws:3.4.1,com.amazonaws:aws-java-sdk-bundle:1.12.367)
[2025-09-09T14:59:11.681+0000] {spark_submit.py:521} INFO - (spark.master,spark://spark-master:7077)
[2025-09-09T14:59:11.682+0000] {spark_submit.py:521} INFO - 
[2025-09-09T14:59:11.686+0000] {spark_submit.py:521} INFO - 
[2025-09-09T14:59:11.842+0000] {spark_submit.py:521} INFO - :: loading settings :: url = jar:file:/home/***/.local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-09-09T14:59:11.951+0000] {spark_submit.py:521} INFO - Ivy Default Cache set to: /home/***/.ivy2.5.2/cache
[2025-09-09T14:59:11.952+0000] {spark_submit.py:521} INFO - The jars for the packages stored in: /home/***/.ivy2.5.2/jars
[2025-09-09T14:59:11.955+0000] {spark_submit.py:521} INFO - org.apache.hadoop#hadoop-aws added as a dependency
[2025-09-09T14:59:11.956+0000] {spark_submit.py:521} INFO - com.amazonaws#aws-java-sdk-bundle added as a dependency
[2025-09-09T14:59:11.956+0000] {spark_submit.py:521} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-bb4e7fb9-52c4-4c18-a728-18e2307ddd6e;1.0
[2025-09-09T14:59:11.956+0000] {spark_submit.py:521} INFO - confs: [default]
[2025-09-09T14:59:16.843+0000] {spark_submit.py:521} INFO - found org.apache.hadoop#hadoop-aws;3.4.1 in central
[2025-09-09T14:59:20.124+0000] {spark_submit.py:521} INFO - found software.amazon.awssdk#bundle;2.24.6 in central
[2025-09-09T14:59:21.745+0000] {spark_submit.py:521} INFO - found org.wildfly.openssl#wildfly-openssl;1.1.3.Final in central
[2025-09-09T14:59:21.768+0000] {spark_submit.py:521} INFO - found com.amazonaws#aws-java-sdk-bundle;1.12.367 in central
[2025-09-09T14:59:22.022+0000] {spark_submit.py:521} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.4.1/hadoop-aws-3.4.1.jar ...
[2025-09-09T14:59:22.822+0000] {spark_submit.py:521} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-aws;3.4.1!hadoop-aws.jar (1040ms)
[2025-09-09T14:59:23.018+0000] {spark_submit.py:521} INFO - downloading https://repo1.maven.org/maven2/software/amazon/awssdk/bundle/2.24.6/bundle-2.24.6.jar ...
[2025-09-09T15:07:17.752+0000] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2025-09-09T15:07:17.849+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-09-09T15:07:17.897+0000] {process_utils.py:132} INFO - Sending 15 to group 2056. PIDs of all processes in the group: [2057, 2056]
[2025-09-09T15:07:17.907+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 2056
[2025-09-09T15:07:17.978+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-09-09T15:07:18.143+0000] {spark_submit.py:647} INFO - Sending kill signal to spark-submit
[2025-09-09T15:07:18.171+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-09-09T15:07:19.047+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=2056, status='terminated', exitcode=0, started='14:59:06') (2056) terminated with exit code 0
[2025-09-09T15:07:19.056+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=2057, status='terminated', started='14:59:07') (2057) terminated with exit code None
